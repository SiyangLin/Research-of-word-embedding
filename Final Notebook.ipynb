{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using classification models for aspect-level sentiment analysis of reviews in Chinese with word embedding and vectorization\n",
    "\n",
    "> This notebook file contains all the code written to obtain the results as described in the thesis report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages\n",
    "> This next cell contains all the packages used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random # to create random numbers/alphabets -> https://docs.python.org/2/library/random.html\n",
    "import pandas as pd #-> https://pandas.pydata.org/\n",
    "import tensorflow as tf # for creating neural networks - > https://www.tensorflow.org/api_docs\n",
    "#from gensim.models.word2vec import Word2Vec\n",
    "import jieba # to cut chinese text -> https://github.com/fxsjy/jieba\n",
    "from collections import Counter # counter -> https://docs.python.org/2/library/collections.html\n",
    "import numpy as np # numpy! ->  https://numpy.org/\n",
    "import os # we use this to navigate directory and read file -> https://docs.python.org/3/library/os.html\n",
    "import pickle # to make file binary -> https://docs.python.org/3/library/pickle.html\n",
    "from gensim.models import Word2Vec # to create vector models of chinese text -> https://radimrehurek.com/gensim/\n",
    "from gensim.models.keyedvectors import KeyedVectors # https://radimrehurek.com/gensim/\n",
    "import logging # https://docs.python.org/3/library/logging.html\n",
    "import keras # for deep learning\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data files\n",
    "> This section imports all the necessary data files used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('sentiment_analysis_trainingset.csv', header = 0, encoding=\"utf-8\")\n",
    "val_set = pd.read_csv('sentiment_analysis_validationset.csv', header = 0, encoding=\"utf-8\")\n",
    "\n",
    "test_set = pd.read_csv('sentiment_analysis_testa.csv', header = 0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"之前评价了莫名其妙被删 果断继续差评！ 换了菜单 价格更低 开始砸牌子 但套餐还是有150...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"出乎意料地惊艳，椰子鸡清热降火，美容养颜，大大满足了爱吃火锅怕上火星人。椰子冻是帅帅的老板...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content  \\\n",
       "0   0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1   1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2   2  \"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...   \n",
       "3   3  \"之前评价了莫名其妙被删 果断继续差评！ 换了菜单 价格更低 开始砸牌子 但套餐还是有150...   \n",
       "4   4  \"出乎意料地惊艳，椰子鸡清热降火，美容养颜，大大满足了爱吃火锅怕上火星人。椰子冻是帅帅的老板...   \n",
       "\n",
       "   location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                            -2                                        -2   \n",
       "1                            -2                                        -2   \n",
       "2                            -2                                        -2   \n",
       "3                            -2                                        -2   \n",
       "4                            -2                                        -2   \n",
       "\n",
       "   location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                     -2                 -2                         1   \n",
       "1                     -2                 -2                        -2   \n",
       "2                     -2                 -2                         0   \n",
       "3                     -2                 -2                        -2   \n",
       "4                     -2                 -2                        -2   \n",
       "\n",
       "   service_parking_convenience  service_serving_speed  price_level  ...  \\\n",
       "0                           -2                     -2           -2  ...   \n",
       "1                           -2                     -2            0  ...   \n",
       "2                           -2                      1            0  ...   \n",
       "3                           -2                     -2            0  ...   \n",
       "4                           -2                     -2           -2  ...   \n",
       "\n",
       "   environment_decoration  environment_noise  environment_space  \\\n",
       "0                      -2                 -2                 -2   \n",
       "1                       0                  0                  0   \n",
       "2                      -2                 -2                  1   \n",
       "3                      -2                 -2                 -2   \n",
       "4                      -2                 -2                 -2   \n",
       "\n",
       "   environment_cleaness  dish_portion  dish_taste  dish_look  \\\n",
       "0                    -2            -2          -2          1   \n",
       "1                     0             1          -2         -2   \n",
       "2                    -2             0           1         -2   \n",
       "3                    -2            -2          -1         -2   \n",
       "4                    -2            -2           1          1   \n",
       "\n",
       "   dish_recommendation  others_overall_experience  \\\n",
       "0                   -2                          1   \n",
       "1                   -2                          1   \n",
       "2                   -2                          0   \n",
       "3                   -2                         -1   \n",
       "4                   -2                          1   \n",
       "\n",
       "   others_willing_to_consume_again  \n",
       "0                               -2  \n",
       "1                               -2  \n",
       "2                               -2  \n",
       "3                               -1  \n",
       "4                               -2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is how the data looks. The column which is the text column in Chinese, is what we have to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Selecting just the text column from the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_shape = val_set.shape[0]\n",
    "train = train_set.iloc[:, 1]\n",
    "val = val_set.iloc[0:7500, 1]\n",
    "test = test_set.iloc[7501:val_shape-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_shape = val_set.shape[0]\n",
    "train = train_set.iloc[:, 1]\n",
    "val = val_set.iloc[0:7500, 1]\n",
    "test = test_set.iloc[7501:val_shape-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to segment the Chinese words, for this a package called jieba will be used\n",
    "> This was inspired from this blog: https://breezegeography.wordpress.com/2018/01/25/how-to-segment-chinese-texts-putting-in-spaces-with-jieba/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# do not run again, it takes couple of hours to completely run this\n",
    "train_words = []\n",
    "\n",
    "for sentences in train:\n",
    "    words = jieba.lcut(sentences, cut_all = True )\n",
    "    train_words.append(\" \".join(words))\n",
    "    \n",
    "val_words = []\n",
    "\n",
    "for sentences in val:\n",
    "    words = jieba.lcut(sentences, cut_all = True )\n",
    "    val_words.append(\" \".join(words))\n",
    "    \n",
    "test_words = []\n",
    "\n",
    "for sentences in test:\n",
    "    words = jieba.lcut(sentences, cut_all = True )\n",
    "    test_words.append(\" \".join(words))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we create a word2vec model from the Chinese embedding file, covering over 8 million Chinese words and phrases.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done\n"
     ]
    }
   ],
   "source": [
    "embedding_model = KeyedVectors.load_word2vec_format(\"Tencent_AILab_ChineseEmbedding.txt\", binary = False)\n",
    "vocab = embedding_model.wv.vocab\n",
    "\n",
    "# do not run again, it takes several hours to completely run this\n",
    "\n",
    "print(\"loading done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, we convert the words to numbers. That is encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words converted to indices\n"
     ]
    }
   ],
   "source": [
    "w2i = {}\n",
    "\n",
    "w2i[\"UNK\"]=1\n",
    "i=2\n",
    "for j in vocab:\n",
    "    w2i[k] = i\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "print(\"words converted to indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then doing the same for the train words, validation words & test words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2i = {}\n",
    "\n",
    "train_2i[\"UNK\"]=1\n",
    "i=2\n",
    "for j in train_words:\n",
    "    train_2i[k] = i\n",
    "    i = i+1\n",
    "    \n",
    "\n",
    "val_2i = {}\n",
    "\n",
    "val_2i[\"UNK\"]=1\n",
    "i=2\n",
    "for j in val_words:\n",
    "    val_2i[k] = i\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "test_2i = {}\n",
    "\n",
    "test_2i[\"UNK\"]=1\n",
    "i=2\n",
    "for j in test_words:\n",
    "    test_2i[k] = i\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices created\n",
      "indices_saved\n"
     ]
    }
   ],
   "source": [
    "# do not run this\n",
    "\n",
    "train_2i = np.zeros((m, max_len))\n",
    "max = 200\n",
    "train_array = np.array(train_words)\n",
    "n = train_array.shape[0]\n",
    "\n",
    "for i in range(n):\n",
    "    sentence = train_words[i]\n",
    "    for j in range(len(sentence)):\n",
    "        if j == max:\n",
    "            break\n",
    "        word = sentence[j]\n",
    "        k=1\n",
    "        if word in vocab:\n",
    "            k = w2i[word]\n",
    "        train_2i[i, j] = k\n",
    "        \n",
    "        \n",
    "val_2i = np.zeros((m, max_len))\n",
    "max = 200\n",
    "val_array = np.array(val_words)\n",
    "n = val_array.shape[0]\n",
    "\n",
    "for i in range(n):\n",
    "    sentence = train_words[i]\n",
    "    for j in range(len(sentence)):\n",
    "        if j == max:\n",
    "            break\n",
    "        word = sentence[j]\n",
    "        k=1\n",
    "        if word in vocab:\n",
    "            k = w2i[word]\n",
    "        val_2i[i, j] = k\n",
    "        \n",
    "\n",
    "test_2i = np.zeros((m, max_len))\n",
    "max = 200\n",
    "test_array = np.array(test_words)\n",
    "n = test_array.shape[0]\n",
    "\n",
    "for i in range(n):\n",
    "    sentence = test_words[i]\n",
    "    for j in range(len(sentence)):\n",
    "        if j == max:\n",
    "            break\n",
    "        word = sentence[j]\n",
    "        k=1 #unk index\n",
    "        if word in vocab:\n",
    "            k = w2i[word]\n",
    "        test_2i[i, j] = k\n",
    "\n",
    "\n",
    "\n",
    "print(\"indices created\")\n",
    "\n",
    "\n",
    "train_2i.dump(\"ti_w2v.dat\")\n",
    "val_2i.dump(\"vi_w2v.dat\")\n",
    "test_2i.dump(\"te_w2v.dat\")\n",
    "\n",
    "\n",
    "print(\"indices_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'content', 'location_traffic_convenience',\n",
       "       'location_distance_from_business_district', 'location_easy_to_find',\n",
       "       'service_wait_time', 'service_waiters_attitude',\n",
       "       'service_parking_convenience', 'service_serving_speed', 'price_level',\n",
       "       'price_cost_effective', 'price_discount', 'environment_decoration',\n",
       "       'environment_noise', 'environment_space', 'environment_cleaness',\n",
       "       'dish_portion', 'dish_taste', 'dish_look', 'dish_recommendation',\n",
       "       'others_overall_experience', 'others_willing_to_consume_again'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns # service_waiters_attitude, dish_taste, others_overall_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_data(length, dim, w2, embedding_model, vocab):\n",
    "    length = length\n",
    "    dim = dim\n",
    "    embedded_matrix = np.zeros((length, dim))\n",
    "    embedded_matrix[1, :] = np.ones((1, dim))\n",
    "    for word, index in word2index.items():\n",
    "        if word in vocab:\n",
    "            emb_matrix[index, :] = embedding_model[word]\n",
    "\n",
    "    return embedded_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models\n",
    "> This section trains and evaluates the classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intial one time data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(file, header=0, encoding=\"utf-8\"):\n",
    "\n",
    "    data_df = pd.read_csv(file, header=header, encoding=encoding)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    \"\"\"\n",
    "    to calculate multiclass roc score\n",
    "    referenced from https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    \n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_load(\"sentiment_analysis_trainingset.csv\")\n",
    "val = data_load(\"sentiment_analysis_validationset.csv\")\n",
    "m_val = val.shape[0]\n",
    "\n",
    "\n",
    "train_doc = train.iloc[:, 1]\n",
    "val_doc = val.iloc[0:7500, 1]\n",
    "test_doc = val.iloc[7501:m_val-1:, 1]\n",
    "\n",
    "\n",
    "train_labels = np.array(train.iloc[:, 2:])\n",
    "val_labels = np.array(val.iloc[0:7500, 2:])\n",
    "test_labels = np.array(val.iloc[7501:m_val-1, 2:])\n",
    "\n",
    "train_sentence_features = np.load(\"train_features.dat\")\n",
    "val_sentence_features = np.load(\"val_features.dat\")\n",
    "test_sentence_features = np.load(\"test_features.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM\n",
    "\n",
    "> This was implemented as a baseline model, inspired from https://github.com/AIChallenger/AI_Challenger_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This 1st model is for the Aspect: Service/Waiters' Attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  0 0.6554666666666666\n",
      "Validation set's F1 score: 0 0.7031047177508272\n",
      "Test set's accuracy rate:  0 0.6524406508402241\n",
      "test set's F1 score: 0 0.7006724358450414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6344760935292431"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_number = 0\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = lin_clf.predict(val_sentence_features)\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "predict = lin_clf.predict(test_sentence_features)\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  3 0.7781333333333333\n",
      "Validation set's F1 score: 3 0.8035068869799499\n",
      "Test set's accuracy rate:  3 0.7720725526807148\n",
      "test set's F1 score: 3 0.7941762215425053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.614206205821898"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_number = 3\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = lin_clf.predict(val_sentence_features)\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "predict = lin_clf.predict(test_sentence_features)\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  8 0.7592\n",
      "Validation set's F1 score: 8 0.6573897597997237\n",
      "Test set's accuracy rate:  8 0.7643371565750867\n",
      "test set's F1 score: 8 0.6641372761762963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5018816817062272"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_number = 8\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = lin_clf.predict(val_sentence_features)\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "predict = lin_clf.predict(test_sentence_features)\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  0 0.8426666666666667\n",
      "Validation set's F1 score: 0 0.8383807535316171\n",
      "Test set's accuracy rate:  0 0.8355561483062149\n",
      "test set's F1 score: 0 0.8303859176222609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5949593356019821"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_number = 0\n",
    "\n",
    "clf = xgb.XGBClassifier(learning_rate=0.1, max_depth=5)\n",
    "clf.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = clf.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "\n",
    "predict = clf.predict(test_sentence_features)\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  3 0.8874666666666666\n",
      "Validation set's F1 score: 3 0.83961908165458\n",
      "Test set's accuracy rate:  3 0.8826353694318485\n",
      "test set's F1 score: 3 0.8328593095183175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5204445873468494"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_number = 3\n",
    "\n",
    "clf = xgb.XGBClassifier(learning_rate=0.1, max_depth=5)\n",
    "clf.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = clf.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "\n",
    "predict = clf.predict(test_sentence_features)\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate val:  8 0.7642666666666666\n",
      "F1 score val: 8 0.6960205979634512\n",
      "Accuracy rate test:  8 0.767938116831155\n",
      "F1 score test: 8 0.7194332312423637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5097780533494374"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_number = 8\n",
    "\n",
    "clf = xgb.XGBClassifier(learning_rate=0.1, max_depth=5)\n",
    "clf.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = clf.predict(val_sentence_features)\n",
    "\n",
    "print(\"Accuracy rate val: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"F1 score val:\", label_number, f1_val)\n",
    "\n",
    "\n",
    "predict = clf.predict(test_sentence_features)\n",
    "# print(\"Accuracy rate: \", sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "print(\"Accuracy rate test: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"F1 score test:\", label_number, f1_test)\n",
    "\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  0 0.8108\n",
      "Validation set's F1 score 0 0.7924395137986145\n",
      "Test set's accuracy rate:  0 0.8027473993064818\n",
      "test set's F1 score: 0 0.7752639470310887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5592288109409941"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "label_number = 0\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(train_sentence_features, train_labels[:, label_number]) \n",
    "\n",
    "predict = rf.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score\", label_number, f1_val)\n",
    "\n",
    "predict = rf.predict(test_sentence_features)\n",
    "\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  3 0.8849333333333333\n",
      "Validation set's F1 score 3 0.835504722753045\n",
      "Test set's accuracy rate:  3 0.8794345158708989\n",
      "test set's F1 score: 3 0.8264611821772441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5067589247554134"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "label_number = 3\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(train_sentence_features, train_labels[:, label_number]) \n",
    "\n",
    "predict = rf.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score\", label_number, f1_val)\n",
    "\n",
    "predict = rf.predict(test_sentence_features)\n",
    "\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate:  8 0.7548\n",
      "Validation set's F1 score 8 0.6753200869488593\n",
      "Test set's accuracy rate:  8 0.7520672179247799\n",
      "test set's F1 score: 8 0.6719191872381992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5064696169513938"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "label_number = 8\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(train_sentence_features, train_labels[:, label_number]) \n",
    "\n",
    "predict = rf.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate: \", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score\", label_number, f1_val)\n",
    "\n",
    "predict = rf.predict(test_sentence_features)\n",
    "\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate: 0 0.8124\n",
      "Validation set's F1 score: 0 0.7908838500666245\n",
      "Test set's accuracy rate:  0 0.801146972526007\n",
      "test set's F1 score: 0 0.77510629863595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5698106930021813"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "label_number = 0\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "knc.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = knc.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate:\", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "predict = knc.predict(test_sentence_features)\n",
    "\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate: 3 0.8816\n",
      "Validation set's F1 score: 3 0.8359981860620342\n",
      "Test set's accuracy rate:  3 0.8770338757001868\n",
      "test set's F1 score: 3 0.8298066546549947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5182398398284616"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "label_number = 3\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "knc.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = knc.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate:\", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "predict = knc.predict(test_sentence_features)\n",
    "\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set's accuracy rate: 8 0.7366666666666667\n",
      "Validation set's F1 score: 8 0.672340926428617\n",
      "Test set's accuracy rate:  8 0.7451320352093892\n",
      "test set's F1 score: 8 0.6837516780693935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5167611069829161"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "label_number = 8\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "knc.fit(train_sentence_features, train_labels[:, label_number])\n",
    "\n",
    "predict = knc.predict(val_sentence_features)\n",
    "\n",
    "print(\"Validation set's accuracy rate:\", label_number, sum(predict==val_labels[:, label_number])/val_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_val=f1_score(val_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"Validation set's F1 score:\", label_number, f1_val)\n",
    "\n",
    "predict = knc.predict(test_sentence_features)\n",
    "\n",
    "\n",
    "print(\"Test set's accuracy rate: \", label_number, sum(predict==test_labels[:, label_number])/test_labels.shape[0])\n",
    "\n",
    "\n",
    "f1_test=f1_score(test_labels[:, label_number], predict, average='weighted', labels=np.unique(predict))\n",
    "print(\"test set's F1 score:\", label_number, f1_test)\n",
    "\n",
    "multiclass_roc_auc_score(test_labels[:, label_number], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to create the one hot encoding for f1 score\n",
    "# written using this guide: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "\n",
    "def onehot_coversion(label, no_class):\n",
    "    list_mat = []\n",
    "    for j in range(len(label)):\n",
    "        label = labels[j]\n",
    "        label = [0 for i in range(no_class)]\n",
    "        types = {\n",
    "        -2: 0,\n",
    "        -1: 1,\n",
    "        0: 2,\n",
    "        1: 3\n",
    "        }\n",
    "        created_label[label_types[label]] = 1\n",
    "        list_mat.append(created_label) \n",
    "    return list_mat\n",
    "\n",
    "\n",
    "def converstion_to_classname(y_oh):\n",
    "    \"\"\"\n",
    "    to get the class name aka the sentiment scores\n",
    "    from one hot encoded integers\n",
    "    \"\"\"\n",
    "    class_index2name = {\n",
    "    0: -2,\n",
    "    1: -1,\n",
    "    2: 0,\n",
    "    3: 1\n",
    "    }\n",
    "\n",
    "    y_list = y_oh.tolist()\n",
    "    result = []\n",
    "    for i in range(len(y_list)):\n",
    "        single_one_hot = y_list[i]\n",
    "\n",
    "        index = single_one_hot.index(1)\n",
    "\n",
    "        class_name = class_index2name.get(index)\n",
    "        result.append(class_name)\n",
    "    return result\n",
    "\n",
    "def converstion_toclassname_ypred(y_prob):\n",
    "    class_index2name = {\n",
    "    0: -2,\n",
    "    1: -1,\n",
    "    2: 0,\n",
    "    3: 1\n",
    "    }\n",
    "\n",
    "    result = []\n",
    "    y_prob = np.matrix(y_prob)\n",
    "    for i in range(y_prob.shape[0]):\n",
    "        single_prob = np.array(y_prob[i, :])\n",
    "        index = np.argmax(single_prob)\n",
    "        class_name = class_index2name.get(index)\n",
    "        result.append(class_name)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = train_labels.shape[1]\n",
    "y_train=np.array(onehot_coversion(train_labels[:, i], 4))\n",
    "y_val=np.array(onehot_coversion(val_labels[:, i], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=400, units=6, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 400))\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 4, init = 'uniform', activation = 'softmax')) \n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.load(\"ti_w2v.dat\")\n",
    "y_train=np.array(convert_to_onehot(train_labels[:, i], 4))\n",
    "y_val=np.array(convert_to_onehot(val_labels[:, i], 4))\n",
    "val_indices = np.load(\"vi_w2v.dat\")\n",
    "test_indices = np.load(\"te_w2v.dat\")\n",
    "max_length=train_indices.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6649 - accuracy: 0.7720 - val_loss: 0.6241 - val_accuracy: 0.7856\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.6401 - accuracy: 0.7751 - val_loss: 0.6107 - val_accuracy: 0.7856\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.6294 - accuracy: 0.7750 - val_loss: 0.6002 - val_accuracy: 0.7861\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.6200 - accuracy: 0.7747 - val_loss: 0.5919 - val_accuracy: 0.7859\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.6144 - accuracy: 0.7743 - val_loss: 0.5907 - val_accuracy: 0.7852\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.6100 - accuracy: 0.7742 - val_loss: 0.5892 - val_accuracy: 0.7843\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.6073 - accuracy: 0.7740 - val_loss: 0.5883 - val_accuracy: 0.7840\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.6051 - accuracy: 0.7736 - val_loss: 0.5928 - val_accuracy: 0.7813\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.6034 - accuracy: 0.7739 - val_loss: 0.5911 - val_accuracy: 0.7829\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.6015 - accuracy: 0.7740 - val_loss: 0.5902 - val_accuracy: 0.7795\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.6003 - accuracy: 0.7740 - val_loss: 0.5896 - val_accuracy: 0.7820\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.5990 - accuracy: 0.7741 - val_loss: 0.5955 - val_accuracy: 0.7805\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.5983 - accuracy: 0.7743 - val_loss: 0.5958 - val_accuracy: 0.7808\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.5972 - accuracy: 0.7741 - val_loss: 0.5932 - val_accuracy: 0.7839\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.5965 - accuracy: 0.7744 - val_loss: 0.6040 - val_accuracy: 0.7765\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.5949 - accuracy: 0.7748 - val_loss: 0.5912 - val_accuracy: 0.7825\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.5948 - accuracy: 0.7745 - val_loss: 0.6078 - val_accuracy: 0.7853\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.5943 - accuracy: 0.7744 - val_loss: 0.5998 - val_accuracy: 0.7843\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.5941 - accuracy: 0.7746 - val_loss: 0.5947 - val_accuracy: 0.7809\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.5936 - accuracy: 0.7745 - val_loss: 0.5941 - val_accuracy: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18d85e3ee80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_indices, y_train, validation_data=(val_indices, y_val), batch_size = 128, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.array(onehot_coversion(test_labels[:, i], 4))\n",
    "scores = classifier.evaluate(test_indices, y_test, verbose=2)\n",
    "y_test_pred = classifier.predict(test_indices, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6141322560550754, 0.7791411280632019]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(test_indices, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    y_pred_label = converstion_toclassname_ypred(y_pred)\n",
    "    y_true_label = converstion_to_classname(y_true)\n",
    "    f1score = f1_score(y_true_label, y_pred_label, average=None)\n",
    "    f1_ave = np.average(f1score)\n",
    "    \n",
    "    \n",
    "    return f1_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_test = f1(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68002434\n"
     ]
    }
   ],
   "source": [
    "f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5004422141276509"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(test_labels[:, i], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=400, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5066 - accuracy: 0.8809 - val_loss: 0.4888 - val_accuracy: 0.8852\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4935 - accuracy: 0.8835 - val_loss: 0.4894 - val_accuracy: 0.8852\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4906 - accuracy: 0.8835 - val_loss: 0.4832 - val_accuracy: 0.8852\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4882 - accuracy: 0.8835 - val_loss: 0.4815 - val_accuracy: 0.8852\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4856 - accuracy: 0.8835 - val_loss: 0.4823 - val_accuracy: 0.8852\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4837 - accuracy: 0.8835 - val_loss: 0.4804 - val_accuracy: 0.8852\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4820 - accuracy: 0.8835 - val_loss: 0.4798 - val_accuracy: 0.8852\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4803 - accuracy: 0.8835 - val_loss: 0.4808 - val_accuracy: 0.8852\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4788 - accuracy: 0.8835 - val_loss: 0.4831 - val_accuracy: 0.8851\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4776 - accuracy: 0.8835 - val_loss: 0.4836 - val_accuracy: 0.8852\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4764 - accuracy: 0.8835 - val_loss: 0.4842 - val_accuracy: 0.8851\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.4756 - accuracy: 0.8836 - val_loss: 0.4887 - val_accuracy: 0.8852\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.4738 - accuracy: 0.8837 - val_loss: 0.4853 - val_accuracy: 0.8852\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.4724 - accuracy: 0.8837 - val_loss: 0.4888 - val_accuracy: 0.8852\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.4719 - accuracy: 0.8837 - val_loss: 0.4903 - val_accuracy: 0.8849\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.4716 - accuracy: 0.8836 - val_loss: 0.4918 - val_accuracy: 0.8851\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.4705 - accuracy: 0.8839 - val_loss: 0.4872 - val_accuracy: 0.8861\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.4694 - accuracy: 0.8842 - val_loss: 0.4925 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.4709 - accuracy: 0.8838 - val_loss: 0.4958 - val_accuracy: 0.8849\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.4688 - accuracy: 0.8842 - val_loss: 0.5048 - val_accuracy: 0.8856\n",
      "f1 test 0.70100344\n",
      "ROC score 0.5037597099600712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "n = train_labels.shape[1]\n",
    "\t#one_hot y\n",
    "y_train=np.array(onehot_coversion(train_labels[:, i], 4))\n",
    "y_val=np.array(onehot_coversion(val_labels[:, i], 4))\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 400))\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 4, init = 'uniform', activation = 'softmax')) \n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "y_train=np.array(convert_to_onehot(train_labels[:, i], 4))\n",
    "y_val=np.array(convert_to_onehot(val_labels[:, i], 4))\n",
    "\n",
    "max_length=train_indices.shape[1]\n",
    "\n",
    "classifier.fit(train_indices, y_train, validation_data=(val_indices, y_val), batch_size = 128, epochs=20, verbose=2)\n",
    "\n",
    "y_test=np.array(onehot_coversion(test_labels[:, i], 4))\n",
    "scores = classifier.evaluate(test_indices, y_test, verbose=2)\n",
    "y_test_pred = classifier.predict(test_indices, verbose=2)\n",
    "\n",
    "classifier.evaluate(test_indices, y_test, verbose=2)\n",
    "\n",
    "f1_test = f1(y_test, y_test_pred)\n",
    "\n",
    "print(\"f1 test\", fl_test)\n",
    "\n",
    "print(\"ROC score\", multiclass_roc_auc_score(test_labels[:, i], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=400, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.7533 - accuracy: 0.7571 - val_loss: 0.7427 - val_accuracy: 0.7599\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.7291 - accuracy: 0.7642 - val_loss: 0.7292 - val_accuracy: 0.7599\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.7248 - accuracy: 0.7642 - val_loss: 0.7244 - val_accuracy: 0.7599\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.7213 - accuracy: 0.7642 - val_loss: 0.7246 - val_accuracy: 0.7599\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.7173 - accuracy: 0.7642 - val_loss: 0.7258 - val_accuracy: 0.7599\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.7152 - accuracy: 0.7642 - val_loss: 0.7262 - val_accuracy: 0.7599\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.7132 - accuracy: 0.7642 - val_loss: 0.7262 - val_accuracy: 0.7599\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.7115 - accuracy: 0.7642 - val_loss: 0.7245 - val_accuracy: 0.7599\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.7103 - accuracy: 0.7642 - val_loss: 0.7293 - val_accuracy: 0.7599\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.7099 - accuracy: 0.7642 - val_loss: 0.7312 - val_accuracy: 0.7599\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.7084 - accuracy: 0.7642 - val_loss: 0.7400 - val_accuracy: 0.7599\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.7077 - accuracy: 0.7642 - val_loss: 0.7436 - val_accuracy: 0.7599\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.7074 - accuracy: 0.7642 - val_loss: 0.7337 - val_accuracy: 0.7599\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.7067 - accuracy: 0.7642 - val_loss: 0.7402 - val_accuracy: 0.7599\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.7063 - accuracy: 0.7642 - val_loss: 0.7355 - val_accuracy: 0.7599\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.7059 - accuracy: 0.7642 - val_loss: 0.7369 - val_accuracy: 0.7599\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.7055 - accuracy: 0.7642 - val_loss: 0.7376 - val_accuracy: 0.7599\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.7049 - accuracy: 0.7642 - val_loss: 0.7343 - val_accuracy: 0.7599\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.7045 - accuracy: 0.7642 - val_loss: 0.7392 - val_accuracy: 0.7599\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.7042 - accuracy: 0.7642 - val_loss: 0.7398 - val_accuracy: 0.7599\n",
      "f1 score 0.6499232\n",
      "ROC score 0.5167611069829161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "n = train_labels.shape[1]\n",
    "\t#one_hot y\n",
    "y_train=np.array(onehot_coversion(train_labels[:, i], 4))\n",
    "y_val=np.array(onehot_coversion(val_labels[:, i], 4))\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 400))\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 4, init = 'uniform', activation = 'softmax')) \n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "y_train=np.array(convert_to_onehot(train_labels[:, i], 4))\n",
    "y_val=np.array(convert_to_onehot(val_labels[:, i], 4))\n",
    "\n",
    "max_length=train_indices.shape[1]\n",
    "\n",
    "classifier.fit(train_indices, y_train, validation_data=(val_indices, y_val), batch_size = 128, epochs=20, verbose=2)\n",
    "\n",
    "y_test=np.array(onehot_coversion(test_labels[:, i], 4))\n",
    "scores = classifier.evaluate(test_indices, y_test, verbose=2)\n",
    "y_test_pred = classifier.predict(test_indices, verbose=2)\n",
    "\n",
    "classifier.evaluate(test_indices, y_test, verbose=2)\n",
    "\n",
    "f1_test = f1(y_test, y_test_pred)\n",
    "\n",
    "print(\"f1 score\", f1_test)\n",
    "\n",
    "print(\"ROC score\", multiclass_roc_auc_score(test_labels[:, i], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to create the data files with train/test/val features as numbers from word matrix\n",
    "# inspired from https://towardsdatascience.com/mapping-word-embeddings-with-word2vec-99a799dc9695\n",
    "\n",
    "# train_features = np.zeros((105000, 400))\n",
    "# val_features = np.zeros((7500, 400))\n",
    "# test_features = np.zeros((7498, 400))\n",
    "\n",
    "# for i in range(105000):\n",
    "#     for j in range(400):\n",
    "#         train_features[i, :] += embedding_matrix[int(train_2i[i, j]), :]\n",
    "\n",
    "\n",
    "# for i in range(7500):\n",
    "#     for j in range(400):\n",
    "#         val_features[i, :] += embedding_matrix[int(val_2i[i, j]), :]\n",
    "\n",
    "\n",
    "# for i in range(7498):\n",
    "#     for j in range(400):\n",
    "#         test_features[i, :] += embedding_matrix[int(test_2i[i, j]), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional References\n",
    "The metrics were calculated with the help of the guide on this website:\n",
    "\n",
    "https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\n",
    "\n",
    "https://pythonprogramming.net/words-as-features-nltk-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
